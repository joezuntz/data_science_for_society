{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-sussex",
   "metadata": {},
   "source": [
    "# Geographic Data With GeoPandas\n",
    "\n",
    "We have previously used the Pandas library to load and explore data.  For geographic data there is an extension to Pandas, called **GeoPandas**, which knows about geographic information, and how to draw maps of it.\n",
    "\n",
    "In this worksheet you will learn to read the most common types of geographic data, and display maps with python\n",
    "\n",
    "There are several other good libraries in python for handling different aspects of geographic data.\n",
    "\n",
    "## Using this notebook\n",
    "\n",
    "- You should already have completed [the numpy notebook](1_Numpy.ipynb), [the matplotlib notebook](2_Matplotlib.ipynb) , and [the pandas notebook](3_Pandas.ipynb) before trying this one.  The layout is the same.\n",
    "\n",
    "\n",
    "- **This notebook is graded: there are 11 exercises**\n",
    "\n",
    "\n",
    "- **Make sure to execute every cell or the ones below may not work**\n",
    "\n",
    "\n",
    "- **Note: This notebook is a fair bit more difficult than previous ones!  It is mainly intended to give you some examples you can use in the intensive hackathon. Don't worry if you find it harder or don't get through it all** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-africa",
   "metadata": {},
   "source": [
    "Before you start, we need to run this cell to install the latest version of geopandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y \"geopandas>=0.9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-recipe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Shape Files for Geographic Data\n",
    "\n",
    "Various quantities can be related to a map - individual points, lines, such as borders, or entire regions, such as political or social divisions.  These can be stored in a *shape file* - a file format that encodes points, lines and polygons on the Earth's surface.  \n",
    "\n",
    "In Pandas we used the `DataFrame` object to store tables of data. In GeoPandas, the equivalent is called a `GeoDataFrame`.  It is a DataFrame with special extra columns and attributes to store geographic information.\n",
    "\n",
    "GeoPandas has a function, `read_file`, specifically to read a shape file into a `GeoDataFrame`.  We will use that, and then the `.head()` method which shows the top few rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = gpd.read_file(\"data/Local_Authority_Districts_(December_2018)_Boundaries_UK_BFC.zip\")\n",
    "regions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-custom",
   "metadata": {},
   "source": [
    "You can see some columns for the name and various coordinates, and also the geometry column, which contains the more details shape information.  We don't have to delve into the details - GeoPandas can just use this information for us.\n",
    "\n",
    "---\n",
    "\n",
    "Anything you can do with a regular Pandas DataFrame you can also do with this GeoDataFrame.\n",
    "\n",
    "## <font color='blue'>Exercise 1</font>  \n",
    "\n",
    "Sort this data frame by the column that represents the area of the local authorities, and find the largest and smalles ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings for the exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-canadian",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# 2. Plotting Maps\n",
    "\n",
    "\n",
    "Now let's go on exploring our data.  GeoPandas lets us visualize all the borders as lines, by making an empty figure with an axis in it, and then\n",
    "passing that to the `regions.plot` method with some choices for the colors and lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-looking",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = regions.plot(facecolor='white', edgecolor='black', linewidth=0.1, figsize=(5,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-oklahoma",
   "metadata": {},
   "source": [
    "That looks familiar.  \n",
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>Exercise 2</font>  \n",
    "\n",
    "\n",
    "Make a version of this plot with:\n",
    "- blue border lines\n",
    "- red filled-in authorities\n",
    "- sensibly labelled x and y axes\n",
    "\n",
    "Hint: The `plot` method returns an axis object which has methods `set_xlabel` and `set_ylabel`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings for the exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-pathology",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# 3. Combining Data\n",
    "\n",
    "Now let's read a second data file that we would like to use in our mapping.  \n",
    "\n",
    "We will need to be able to match it in some\n",
    "way to our regions information, so we should use something that is also organise by local authority.  In particular, let's use some demographic data about age distributions in the UK.  This is a regular comma-separated values file (CSV) that we will read with standard Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = pd.read_csv(\"data/age_distributions_2018.csv.gz\")\n",
    "ages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-registration",
   "metadata": {},
   "source": [
    "This looks sensible.  It has different columns for each possible age, and Male `M`, Female `F` and All `A` columns.\n",
    "\n",
    "---\n",
    "\n",
    "Let's plot something simple and non-geographic: a histogram of the populations of local authorities.  We can use the `hist` method of the data frames we just loaded (this is specific variant of the `plot` method we used in the last exercise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ages.hist('ATotal', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-short",
   "metadata": {},
   "source": [
    "Hmm.  Not great.  There's one row with about 65 million people in, and all the rest much closer to zero.\n",
    "\n",
    "---\n",
    "\n",
    "Here's where our domain-specific knowledge comes in: we recognise that number as the total UK population.  There must be a row for the whole UK.\n",
    "\n",
    "## <font color='blue'>Exercise 3</font>  \n",
    "\n",
    "\n",
    "Replaces `ages` variable with a new version that doesn't have this row in.  There are a few ways you could do this - you could figure out which row it is and use `ages.drop`, or you could `query` all rows with ATotal less than (e.g.) 50 million,.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings for the exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-senegal",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now let's merge our region data with our age distribution data.  We use the GeoPandas `merge` method, with the names of the two columns we want to match together.  These are called the left and right columns, because we imagine one table on the left-hand side and matching up row by row with another table on the right-hand side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = regions.merge(ages, left_on='lad18nm', right_on='Local Authority')\n",
    "match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-shopping",
   "metadata": {},
   "source": [
    "It looks like something has worked and we've managed to match the two tables.  \n",
    "\n",
    "Let's check by plotting the borders again, from this new matched table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "match.plot(figsize=(5,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-onion",
   "metadata": {},
   "source": [
    "Wales is missing!  \n",
    "\n",
    "That must mean that when we did the match the names of places in Wales were not paired up. Let's try to figure out why - you might have a guess already.\n",
    "\n",
    "---\n",
    "\n",
    "We can speed up our search a lot using python `sets`.  A set is a structure of data that makes it very quick to check whether a particular object is in the set (if we were using an array or a list we would have to search through all the data every single time, which is slow.  Sets use a lookup table to make it faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a set of each set of names\n",
    "region_names = set(regions['lad18nm'])\n",
    "ages_names = set(ages['Local Authority'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-oasis",
   "metadata": {},
   "source": [
    "## <font color='blue'>Exercise 4</font>  \n",
    "\n",
    "\n",
    "a) Write two python loops, one through each of these two sets.  In each case, check if the loop variable is contained in the *other* set, and print out if it is not.\n",
    "\n",
    "Hint: the python syntax `x in y` checks if the item `x` is in the set `y` and evaluates as `True` or `False`.\n",
    "\n",
    "b) Write down an explanation of the problem with the matching that this reveals.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings on this exercise part (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your explanation of the problem part (b)\n",
    "# write your answer as a comment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-myanmar",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# 4. Choropleths\n",
    "\n",
    "Your diagnosis now lets us fix the problem, by making a new column in the `ages` table with a \"fixed\" name.  \n",
    "This kind of data cleaning is the bulk of real-world data analysis!\n",
    "\n",
    "We will use a python *list comprehension* to make the new column values in a list, and then we can easily create the new column.  For convenience we can give it the same name as the regions table, so that the merge command is even simpler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes a list for each local authority name, consisting of the item, split my the '/' character,\n",
    "# and then with the extra space stripped off\n",
    "new_column = [name.split('/')[0].strip() for name in ages['Local Authority']]\n",
    "\n",
    "# Add our new column\n",
    "ages['lad18nm'] = new_column\n",
    "\n",
    "# Make a new match\n",
    "match2 = regions.merge(ages, on='lad18nm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-navigation",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Now we have hopefully fixed Wales we can use GeoPandas to plot a specific colour for a specific column.  This kind of geographic map of a numeric quantity is called a *choropleth*.\n",
    "\n",
    "Let's look at a choropleth of the total population of each local authority.  Play around with this method and see what options you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "match2.plot('ATotal', legend=True, figsize=(5,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now lets explore the gender ratio in different parts of the UK.\n",
    "\n",
    "## <font color='blue'>Exercise 5</font>  \n",
    "\n",
    "\n",
    "Make a new column in the `match2` table which contains the ratio of the total number of men to the total number of women, and then make a map of that ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings for the exercise \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-salmon",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# 5. Individual Locations\n",
    "\n",
    "Now lets look at some point-like data (i.e. individual locations, instead of lines or regions), and learn how to convert it to the kind of maps above.\n",
    "\n",
    "We will load the location of every post office in the United Kingdom from a new CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_offices = pd.read_csv(\"data/pol-branch-listings-2020-02-20.csv.gz\")\n",
    "post_offices.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-intake",
   "metadata": {},
   "source": [
    "You can ignore any warning that appears; it doesn't matter here. What does matter is that each post offices appears in the list multiple times, once for each day of the week that it is open.  We should fix that.\n",
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>Exercise 6</font>  \n",
    "\n",
    "Replace the `post_offices` variable with one with the duplicates for each location removed.\n",
    "Hint: Consult the documentation for the `drop_duplicates` method of pandas data frames, and figure out which column to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings for exercise 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-marking",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The post_offices variable is still a Pandas data frame; it is not a GeoPandas object with full coordinates yet.  But it is in latitude/longitude coordinates, so we can plot those:\n",
    "\n",
    "\n",
    "## <font color='blue'>Exercise 7</font>  \n",
    "\n",
    "Make a basic Pandas scatter plot of the longitude vs latitude in the `post_offices` table.\n",
    "\n",
    "Hint: Set the keyword `s=0.1` to make the size of each point smaller so it is easier to see them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings for this exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-midnight",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "To convert to a full GeoDataFrame we have to first make a geometry object that describes the location.  GeoPandas has a function to do this for us, `points_from_xy`.  We can use this to make a full GeoPandas GeoDataFrame.\n",
    "\n",
    "We also (optionally; this will be useful later) tell GeoPandas what *coordinate reference system* (CRS) we are working in. The most common latitude and longitude system in geo data files is called `WGS84`, sometimes also called by the code name `epsg:4326`.  If you just have a general latitude and longitude then this is the system it will almost certainly use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = gpd.points_from_xy(post_offices['BRANCH_LONGITUDE'], post_offices['BRANCH_LATITUDE'], crs='epsg:4326')\n",
    "post_offices = gpd.GeoDataFrame(post_offices, geometry=geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-davis",
   "metadata": {},
   "source": [
    "# 6. Coordinate Systems\n",
    "\n",
    "Now we can plot our local authorities on the same plot as our post offices.  We have to set the face color to \"none\" so that it doesn't draw over the post office points when it draws the local authorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = post_offices.plot(markersize=0.1, color='red', figsize=(6, 8))\n",
    "regions.plot(facecolor='none', edgecolor='black', linewidth=0.1, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-instruction",
   "metadata": {},
   "source": [
    "This doesn't look right.  If you look closely you will see that the red dots for the post offices are all down at coordinates (0, 0).  That gives us a clue as to what has happened - all our maps of the local authorities are in meters, with the zero point at the southern and western corner of the UK, but our post office plot was in degrees latitude and longitude.\n",
    "\n",
    "This is a problem with coordinate systems.  We need to convert either one to match the other.\n",
    "\n",
    "## <font color='blue'>Exercise 8</font>  \n",
    "\n",
    "Use the `post_offices.to_crs` method to convert the post-office data to a new variable `post_offices2` with the same CRS as the regions data.\n",
    "\n",
    "You will need to figure out how to get the CRS information object from the `regions` table.\n",
    "\n",
    "Hint: In the cell below type `regions.` and then press the Tab key on your keyboard.  This will give you a list you can scroll through of all the attributes of the regions variable.  Look for one that could be the CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings on this exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-light",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If that has worked you will now be able to make a much more sensible looking plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 8))\n",
    "post_offices2.plot(markersize=0.1, color='red', ax=ax)\n",
    "regions.plot(facecolor='none', edgecolor='black', linewidth=0.1, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-choice",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Spatial Joins\n",
    "\n",
    "Geographical relationships in GeoPandas, like checking whether a point is inside a region, or whether two regions intersect, are done using a *spatial join*, using the `sjoin` function.  It makes a new table, with the combined columns of the two input (points and regions).  The rows of the table are all the cases where there is a match.\n",
    "\n",
    "The first few columns will be the same for each row in what is printed below\n",
    "\n",
    "(In this case because local authorities don't overlap, each post office will only be in a single region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_table = gpd.sjoin(regions, post_offices2, how=\"inner\", op='contains')\n",
    "match_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-update",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now we have made this matched table we can make a new column in our regions data, and fill it with the\n",
    "number of post offices in that region.  There are a few ways we could do that.  Here, we will loop through the different regions and find all the post offices in it one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "match2['post_office_count'] = np.zeros(len(regions))\n",
    "for i in regions.index:\n",
    "    name = match2.at[i, \"lad18nm\"]\n",
    "    # This is a series of True/False values indicating whether reach row in the match\n",
    "    # table as the same name as our curent region\n",
    "    matched_rows = (match_table['lad18nm'] == name)\n",
    "    # In python True counts as 1 and False as 0 for the purposes\n",
    "    # of arithmetic.  So if we sum up all the values then that is the\n",
    "    # True in the series.\n",
    "    matched_count = matched_rows.sum()\n",
    "    match2.at[i, \"post_office_count\"] = matched_count\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-miller",
   "metadata": {},
   "source": [
    "## <font color='blue'>Exercise 9</font>  \n",
    "\n",
    "Make a new column in the `match2` table showing the number of people per post office in the authority, and display a map of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings on this exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-small",
   "metadata": {},
   "source": [
    "# 8. Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-twist",
   "metadata": {},
   "source": [
    "We frequently don't have a latitude and longitude in our data sets, but some other location information, such as an address, postcode, or place name.\n",
    "\n",
    "The process of turning information like this into a latitude & longitude that we can map is called *geocoding*.  To perform general geocoding we have to use one of various web services.  These services usually either limit your usage (e.g. 100 postcodes per day) or cost money, though not typically very much.\n",
    "\n",
    "## <font color='blue'>Exercise 10</font>  \n",
    "\n",
    "Use the GeoPandas function `gpd.tools.geocode` to make a variable called `d` of the latitude and longitude of the Edinburgh Futures Institute, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings on this exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-virus",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Now we have this location we can plot it on our map.  We have to convert coordinates again first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.to_crs(regions.crs)\n",
    "ax = regions.plot(figsize=(5,8))\n",
    "d2.plot(ax=ax, color='red', marker='x', markersize=200)\n",
    "ax.set_xlim(2e5, 5e5)\n",
    "ax.set_ylim(6e5, 8e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-register",
   "metadata": {},
   "source": [
    "For UK postcode data in particular we can instead download the full postcode data base, subject to a licenses.\n",
    "\n",
    "If you like, and the file is not too large, have a go reading the file `data/NSPL_NOV_2020_UK.csv.gz` and finding the latitude and longitude of the Edinburgh Furniture Initiative at EH7 4HF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-leone",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. Wrapping up\n",
    "\n",
    "You're now ready for the hackathon!\n",
    "\n",
    "## <font color='blue'>Exercise 11</font>  \n",
    "\n",
    "Explore & play.  Do something interesting with the data you've loaded so far; either plot something, or look at the methods of geopandas data sets and see what you can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your workings on this exercise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
